---
title: "Analysis of Thinness in Children Across Various Socioeconomic Factors"
author: "Anita Hessami Pilehrood, Isabelle Liu, Christian Hardat"
subtitle: "STA302 - Fall 2023 - Project"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: pdf_document
---

```{r, include=FALSE}
# Load necessary libraries
library(readr)
library(dplyr)
library(ggplot2)
packageurl <- "https://cran.r-project.org/src/contrib/Archive/pbkrtest/pbkrtest_0.4-4.tar.gz" 
install.packages(packageurl, repos=NULL, type="source")
install.packages("car", dependencies=TRUE)
library(car)
install.packages("psych")
library(psych)
install.packages("MASS")
library(MASS)
install.packages("leaps")
library(leaps)

```

```{r}
data <- read.csv("STA302 Part 3 Cleaned Dataset.csv")

new <- subset(as.data.frame(data), 
              select = c(Thinness, Hepatitis_B, Measles, 
                         Healthcare_Expenditure, Status_name, Schooling))

data <- new[complete.cases(new),]

# Convert categorical variables to factors
data$Status_name <- as.factor(data$Status_name)

# Create dummy variables for categorical predictors
data <- model.matrix(~ . - 1, data = data)
data <- data.frame(data)

# Define the model formula
model_formula <- Thinness ~ Hepatitis_B + Measles + Healthcare_Expenditure + Schooling + Status_nameDeveloping

# Fit the linear model to the entire dataset
model <- lm(model_formula, data = data)

# Summary of the model
summary(model)

```

```{r}
# Extract fitted/predicted values 
y_hat <- fitted(model)
# Extract residuals from the model
e_hat <- resid(model)


######## Response vs. Fitted Values Scatterplot (Conditional Mean Response)
# Plot the observed values vs. the fitted values
plot(x = y_hat, y = data$Thinness,
     xlab = "Fitted Values",
     ylab = "Thinness",
     main = "Thiness vs. Fitted"
)

# Adding a line of perfect fit for reference
abline(0, 1, col = "red", lwd = 2, lty = 2)


###### Pairwise Scatterplots of Predictors (Conditonal Mean Predictors)
pairs(data[, c(2, 3, 4, 6, 7)], main = "Pairwise Scatterplots of Predictors")

par(mfrow=c(2,2))
# scatterplot of residuals versus fitted values
plot(y_hat, e_hat, main="Residuals vs Fitted", xlab="Fitted", ylab="Residuals")

# scatterplot of residuals versus each predictor
plot(data$Hepatitis_B, e_hat, main="Residuals vs Hepatitis_B", xlab="Hepatitis_B", ylab="Residuals")

plot(data$Measles, e_hat, main="Residuals vs Measles", xlab="Measles", ylab="Residuals")

plot(data$Healthcare_Expenditure, e_hat, main="Residuals vs Healthcare", xlab="Healthcare", ylab="Residuals")

plot(data$Schooling, e_hat, main="Residuals vs Schooling", xlab="Schooling ", ylab="Residuals")

# boxplot of residuals vs Developing
boxplot(e_hat ~ data$Status_nameDeveloping, main="Residuals by Developing", xlab="Developing", ylab="Residuals")


# Normal QQ plot
qqnorm(e_hat)
qqline(e_hat)

# Histogram 
hist(data$Thinness, main="Histogram", xlab="Thinness")
```

```{r}
# boxCox plot
boxCox(model)

#powerTransform 
any(data$Measles <= 0)
constant_value <- 0.0001
data$adjMeasles <- data$Measles + constant_value
p <- powerTransform(data$adjMeasles)
summary(p)

#### Cube root(Thinness) & log(Measles) Transformation 
data$root_Thinness <- (data$Thinness)^(1/3) 
data$log_Measles <- log(data$Measles + 1) # Adding 1 to avoid log(0)

# Fit the model with the transformed response variable
model_root <- lm(root_Thinness ~ Hepatitis_B + log_Measles + Healthcare_Expenditure + Schooling + Status_nameDeveloping, data = data)

par(mfrow=c(2,2))
# Check the new residuals vs. fitted values plot
plot(fitted(model_root), resid(model_root),
     xlab = "Fitted Values", ylab = "Residuals",
     main = "Residuals vs. Fitted Values \nafter Root Transformation")
abline(h = 0, col = "red", lty = 2)

eroot_hat <- resid(model_root)
# Normal QQ plot
qqnorm(eroot_hat)
qqline(eroot_hat)

# Scatterplot of Residual vs. Measles of transformed model 
plot(data$log_Measles, eroot_hat, main="Residuals vs Measles \nafter Root Transformation", xlab="Measles", ylab="Residuals")

# scatterplot of residuals versus each predictor
plot(data$Hepatitis_B, eroot_hat, main="Residuals vs Hepatitis_B", xlab="Hepatitis_B", ylab="Residuals")

plot(data$Healthcare_Expenditure, eroot_hat, main="Residuals vs Healthcare", xlab="Healthcare", ylab="Residuals")

plot(data$Schooling, eroot_hat, main="Residuals vs Schooling", xlab="Schooling ", ylab="Residuals")

# boxplot of residuals vs Developing
boxplot(eroot_hat ~ data$Status_nameDeveloping, main="Residuals by Developing", xlab="Developing", ylab="Residuals")

# Histogram of transformed model
hist(data$root_Thinness, main="Histogram", xlab="Cube root(Thinness)")

y_root <- fitted(model_root)

```

```{r}
######## Response vs. Fitted Values Scatterplot (Conditional Mean Response)
# Plot the observed values vs. the fitted values
plot(x = y_root, y = data$root_Thinness,
     xlab = "Fitted Values",
     ylab = "Thinness",
     main = "Thiness vs. Fitted"
)

# Adding a line of perfect fit for reference
abline(0, 1, col = "red", lwd = 2, lty = 2)


###### Pairwise Scatterplots of Predictors (Conditional Mean Predictors)
pairs(data[, c(2, 10, 4, 6, 7)], main = "Pairwise Scatterplots of Predictors")

summary(model_root)
qf(0.95, 5, 2564)
summary(model_root)
```

```{r}
model_reduce <- lm(root_Thinness ~ log_Measles + Healthcare_Expenditure + Schooling + Status_nameDeveloping, data = data)
anova(model_reduce, model_root)
qf(0.95, 1, 2564)


############### Reduce model Assumption Checks 
# Extract fitted/predicted values 
y2_hat <- fitted(model_reduce)
# Extract residuals from the model
e2_hat <- resid(model_reduce)

par(mfrow=c(2,2))
# scatterplot of residuals versus fitted values
plot(y2_hat, e2_hat, main="Residuals vs Fitted", xlab="Fitted", ylab="Residuals")

# scatterplot of residuals versus each predictor
plot(data$log_Measles, e2_hat, main="Residuals vs Measles", xlab="Measles", ylab="Residuals")

plot(data$Healthcare_Expenditure, e2_hat, main="Residuals vs Healthcare", xlab="Healthcare", ylab="Residuals")

plot(data$Schooling, e2_hat, main="Residuals vs Schooling", xlab="Schooling ", ylab="Residuals")

# boxplot of residuals vs Developing
boxplot(e2_hat ~ data$Status_nameDeveloping, main="Residuals by Developing", xlab="Developing", ylab="Residuals")


# Normal QQ plot
qqnorm(e2_hat)
qqline(e2_hat)
```

```{r}
# Model selection using stepwise selection
stepAIC(lm(root_Thinness ~ 1,data=data[,-1]),
        scope=list(upper=lm(data$root_Thinness ~ .,data=data[,-1])),
        direction = "both", k=5)

```

```{r}

best <- regsubsets(root_Thinness ~ Hepatitis_B + log_Measles + 
                     Healthcare_Expenditure + Status_nameDeveloping + Schooling,
                   data = data, nbest = 1, nvmax=5)
summary(best)


subsets(best, statistic = "adjr2", legend=TRUE)

```

```{r}
# Checking for problematic observations in our transformed model
model_root <- lm(root_Thinness ~ Hepatitis_B + log_Measles + 
                         Healthcare_Expenditure + Schooling +
                         Status_nameDeveloping, data = data)
model_root
```

```{r}
# Defining the cutoffs
# useful values:
n <- nrow(data)
p <- length(coef(model_root))-1

# leverage cutoff
h_cut <- 2*(p+1)/n 

# cooks cutoff
D_cut <- qf(0.5, p+1, n-p-1) 

# DFFITS cutoff
fits_cut <- 2*sqrt((p+1)/n)

# DFBETAS cutoff
beta_cut <- 2/sqrt(n)

#Compute the measures for each problematic observation on transformed model
# leverage
h_ii <- hatvalues(model_root) 

# outlier
r_i <- rstandard(model_root) 

# Cook's Distance
D_i <- cooks.distance(model_root) 

# DFFITS
dffits_i <- dffits(model_root)

# DFBETAS
dfbetas_i <- dfbetas(model_root)

```

```{r}
# identify leverage points
which(h_ii > h_cut)
```

```{r}
# identify outliers
which(r_i > 4 | r_i < -4)
```

```{r}
# influential on all fitted values
which(D_i > D_cut)
```

```{r}
# influential on own fitted value
which(abs(dffits_i) > fits_cut)
```

```{r}
# influential on a coefficient
for(i in 1:6){
        print(paste0("Beta ", i-1))
        print(which(abs(dfbetas_i) > beta_cut))
}
```


```{r}
# Find number of rows in order to split data in half for random sampling
nrow(data)

# Split data in half
s <- sample(1:nrow(data), 1285 , replace=F) 
train <- data[s ,]
test <- data[-s,]
```

```{r}
# Numerical summaries of variables in model
describe(train)
describe(test)
```

```{r}
# Fit final selected model 

final <- lm(root_Thinness ~ log_Measles + Healthcare_Expenditure + Schooling +
              Status_nameDeveloping, data = train ) 

# check conditions
pairs(train[,c(10, 4, 6, 7)])
plot(train$root_Thinness ~ fitted(final))
```

```{r}
# Check assumptions
par(mfrow=c(3,2))
plot(resid(final)~fitted(final), xlab="fitted", ylab="residuals") 
for(i in c(10, 4, 6, 7)){
        plot(resid(final) ~ train[,i], xlab=names(train)[i], ylab="residuals")
}
qqnorm(resid(final))
qqline(resid(final))
```

```{r}
# Multicollinearity
vif(final)
```

```{r}
# a function that will compute problematic observations for you
probobs <- function(model, data){ 
        n_1 <- nrow(data)
        p <- length(coef(model))-1
# leverage cutoff
        h_cut <- 2*(p+1)/n
        print(which(hatvalues(model) > h_cut))
# outliers
        print("outliers (large)")
        print(which(rstandard(model) > 4 | rstandard(model) < -4)) 
# cooks cutoff
        D_cut <- qf(0.5, p+1, n-p-1)
        print("Cooks")
        print(which(cooks.distance(model) > D_cut))
# DFFITS cutoff
        fits_cut <- 2*sqrt((p+1)/n)
        print("DFFITS")
        print(which(abs(dffits(model)) > fits_cut))
# DFBETAS cutoff
        beta_cut <- 2/sqrt(n)
        for(i in 1:(p+1)){
                print(paste0("Beta ", i-1))
                print(which(abs(dfbetas(model)[,i]) > beta_cut)) 
                }
}
# to use the function, run above and this next line:
probobs(final, train)
```

```{r}
summary(final)
```

```{r}
# Fit final model using test dataset 

final_test <- lm(root_Thinness ~ log_Measles + Healthcare_Expenditure + 
                   Schooling + Status_nameDeveloping, data = test ) 
summary(final_test)
```

```{r}
# check conditions for test
pairs(test[,c(10, 4, 6, 7)])
plot(test$root_Thinness ~ fitted(final_test))
```

```{r}
# check assumptions
par(mfrow=c(3,2))
plot(resid(final_test)~fitted(final_test), xlab="fitted", ylab="residuals") 
for(i in c(10, 4, 6, 7)){
        plot(resid(final_test) ~ test[,i], xlab=names(test)[i], ylab="residuals") 
}

qqnorm(resid(final_test)) 
qqline(resid(final_test))

# multicollinearity
vif(final_test)
```

```{r}
# problematic observations for test dataset
probobs(final_test, test)
```

```{r}
# Confidence table for final selected model
confint(model_reduce)
```

